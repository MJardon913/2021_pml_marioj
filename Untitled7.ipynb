{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "id": "dd8896e2-8926-4d36-ba96-8401bbcfa65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40c123-a2bb-494c-85a3-1c3fa3a205d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ecaee58-6f15-4766-9b22-09619c707724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.63\n",
      "Accuracy on test set: 0.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)\n",
    "svc = SVC(kernel=\"rbf\", C=0.01, gamma=100)\n",
    "svc.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.2f}\".format(svc.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "233b7564-92ac-4d8c-89e8-3e31f6591a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum for each feature\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Maximum for each feature\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# compute the minimum value per feature on the training set\n",
    "min_on_training = X_train.min(axis=0)\n",
    "# compute the range of each feature (max - min) on the training set\n",
    "range_on_training = (X_train - min_on_training).max(axis=0)\n",
    "# subtract the min, and divide by range\n",
    "# afterward, min=0 and max=1 for each feature\n",
    "X_train_scaled = (X_train - min_on_training) / range_on_training\n",
    "print(\"Minimum for each feature\\n{}\".format(X_train_scaled.min(axis=0)))\n",
    "print(\"Maximum for each feature\\n {}\".format(X_train_scaled.max(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13fd34f5-f07e-4962-affc-f9ffbd42c532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum for each feature\n",
      "[ 0.03540158  0.04190871  0.02895446  0.01497349  0.14260888  0.04999658\n",
      "  0.          0.          0.07222222  0.00589722  0.00105015 -0.00057494\n",
      "  0.00067851 -0.0007963   0.05148726  0.01434497  0.          0.\n",
      "  0.04195752  0.01113138  0.03678406  0.01252665  0.03366702  0.01400904\n",
      "  0.08531995  0.01833687  0.          0.          0.00749064  0.02367834]\n",
      "Maximum for each feature\n",
      " [0.76809125 1.22697095 0.75813696 0.64750795 1.20310633 1.11643038\n",
      " 0.99906279 0.90606362 0.93232323 0.94903117 0.45573058 0.72623944\n",
      " 0.48593507 0.31641282 1.36082713 1.2784499  0.36313131 0.77476795\n",
      " 1.32643996 0.72672498 0.82106012 0.87553305 0.77887345 0.67803775\n",
      " 0.78603975 0.87843331 0.93450479 1.0024113  0.76384782 0.58743277]\n"
     ]
    }
   ],
   "source": [
    "# use THE SAME transformation on the test set,\n",
    "# using min and range of the training set (see Chapter 3 for details)\n",
    "X_test_scaled = (X_test - min_on_training) / range_on_training\n",
    "print(\"Minimum for each feature\\n{}\".format(X_test_scaled.min(axis=0)))\n",
    "print(\"Maximum for each feature\\n {}\".format(X_test_scaled.max(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4179e080-06ad-4b33-8beb-cf6beedf4cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.629\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=100, gamma=100)\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svc.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(svc.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbf9b6fd-0c5a-426a-8af6-67c3c295098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d3ce0a3-bc01-4fee-9844-daae5a316ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Feature 1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#In[93]:\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=100, noise=0.25, random_state=3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "random_state=42)\n",
    "mlp = MLPClassifier(solver='lbfgs', random_state=0).fit(X_train, y_train)\n",
    "mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe04ee7-d59b-4e8b-8339-014c99ffbad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Feature 1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#In[94]:\n",
    "mlp = MLPClassifier(solver='lbfgs', random_state=0, hidden_layer_sizes=[10])\n",
    "mlp.fit(X_train, y_train)\n",
    "mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97e0526-707e-4f3f-8106-36a367e9873f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "print(mlp.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc86e93-9ca2-4123-bd5e-9ff1e39b67cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n"
     ]
    }
   ],
   "source": [
    "print(mlp.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30423651-3a01-4d39-9310-b2a68172329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.867\n",
      "Accuracy on test set: 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mario/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#In[101]:\n",
    "# compute the mean value per feature on the training set\n",
    "mean_on_train = X_train.mean(axis=0)\n",
    "# compute the standard deviation of each feature on the training set\n",
    "std_on_train = X_train.std(axis=0)\n",
    "# subtract the mean, and scale by inverse standard deviation\n",
    "# afterward, mean=0 and std=1\n",
    "X_train_scaled = (X_train - mean_on_train) / std_on_train\n",
    "# use THE SAME transformation (using training mean and std) on the test set\n",
    "X_test_scaled = (X_test - mean_on_train) / std_on_train\n",
    "mlp = MLPClassifier(random_state=0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(\n",
    "mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e3d2cb4-8d09-4d97-93a7-127871c67750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.867\n",
      "Accuracy on test set: 0.720\n"
     ]
    }
   ],
   "source": [
    "#In[103]:\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (100,3), activation='tanh', max_iter=1000, alpha=1, random_state=0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(\n",
    "mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10356b66-f868-4d81-bfc5-7a1afa0639a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MLPClassifier in module sklearn.neural_network._multilayer_perceptron:\n",
      "\n",
      "class MLPClassifier(sklearn.base.ClassifierMixin, BaseMultilayerPerceptron)\n",
      " |  MLPClassifier(hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |  \n",
      " |  Multi-layer Perceptron classifier.\n",
      " |  \n",
      " |  This model optimizes the log-loss function using LBFGS or stochastic\n",
      " |  gradient descent.\n",
      " |  \n",
      " |  .. versionadded:: 0.18\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  hidden_layer_sizes : tuple, length = n_layers - 2, default=(100,)\n",
      " |      The ith element represents the number of neurons in the ith\n",
      " |      hidden layer.\n",
      " |  \n",
      " |  activation : {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
      " |      Activation function for the hidden layer.\n",
      " |  \n",
      " |      - 'identity', no-op activation, useful to implement linear bottleneck,\n",
      " |        returns f(x) = x\n",
      " |  \n",
      " |      - 'logistic', the logistic sigmoid function,\n",
      " |        returns f(x) = 1 / (1 + exp(-x)).\n",
      " |  \n",
      " |      - 'tanh', the hyperbolic tan function,\n",
      " |        returns f(x) = tanh(x).\n",
      " |  \n",
      " |      - 'relu', the rectified linear unit function,\n",
      " |        returns f(x) = max(0, x)\n",
      " |  \n",
      " |  solver : {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
      " |      The solver for weight optimization.\n",
      " |  \n",
      " |      - 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
      " |  \n",
      " |      - 'sgd' refers to stochastic gradient descent.\n",
      " |  \n",
      " |      - 'adam' refers to a stochastic gradient-based optimizer proposed\n",
      " |        by Kingma, Diederik, and Jimmy Ba\n",
      " |  \n",
      " |      Note: The default solver 'adam' works pretty well on relatively\n",
      " |      large datasets (with thousands of training samples or more) in terms of\n",
      " |      both training time and validation score.\n",
      " |      For small datasets, however, 'lbfgs' can converge faster and perform\n",
      " |      better.\n",
      " |  \n",
      " |  alpha : float, default=0.0001\n",
      " |      L2 penalty (regularization term) parameter.\n",
      " |  \n",
      " |  batch_size : int, default='auto'\n",
      " |      Size of minibatches for stochastic optimizers.\n",
      " |      If the solver is 'lbfgs', the classifier will not use minibatch.\n",
      " |      When set to \"auto\", `batch_size=min(200, n_samples)`\n",
      " |  \n",
      " |  learning_rate : {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
      " |      Learning rate schedule for weight updates.\n",
      " |  \n",
      " |      - 'constant' is a constant learning rate given by\n",
      " |        'learning_rate_init'.\n",
      " |  \n",
      " |      - 'invscaling' gradually decreases the learning rate at each\n",
      " |        time step 't' using an inverse scaling exponent of 'power_t'.\n",
      " |        effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
      " |  \n",
      " |      - 'adaptive' keeps the learning rate constant to\n",
      " |        'learning_rate_init' as long as training loss keeps decreasing.\n",
      " |        Each time two consecutive epochs fail to decrease training loss by at\n",
      " |        least tol, or fail to increase validation score by at least tol if\n",
      " |        'early_stopping' is on, the current learning rate is divided by 5.\n",
      " |  \n",
      " |      Only used when ``solver='sgd'``.\n",
      " |  \n",
      " |  learning_rate_init : double, default=0.001\n",
      " |      The initial learning rate used. It controls the step-size\n",
      " |      in updating the weights. Only used when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  power_t : double, default=0.5\n",
      " |      The exponent for inverse scaling learning rate.\n",
      " |      It is used in updating effective learning rate when the learning_rate\n",
      " |      is set to 'invscaling'. Only used when solver='sgd'.\n",
      " |  \n",
      " |  max_iter : int, default=200\n",
      " |      Maximum number of iterations. The solver iterates until convergence\n",
      " |      (determined by 'tol') or this number of iterations. For stochastic\n",
      " |      solvers ('sgd', 'adam'), note that this determines the number of epochs\n",
      " |      (how many times each data point will be used), not the number of\n",
      " |      gradient steps.\n",
      " |  \n",
      " |  shuffle : bool, default=True\n",
      " |      Whether to shuffle samples in each iteration. Only used when\n",
      " |      solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Determines random number generation for weights and bias\n",
      " |      initialization, train-test split if early stopping is used, and batch\n",
      " |      sampling when solver='sgd' or 'adam'.\n",
      " |      Pass an int for reproducible results across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for the optimization. When the loss or score is not improving\n",
      " |      by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,\n",
      " |      unless ``learning_rate`` is set to 'adaptive', convergence is\n",
      " |      considered to be reached and training stops.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Whether to print progress messages to stdout.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous\n",
      " |      call to fit as initialization, otherwise, just erase the\n",
      " |      previous solution. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  momentum : float, default=0.9\n",
      " |      Momentum for gradient descent update. Should be between 0 and 1. Only\n",
      " |      used when solver='sgd'.\n",
      " |  \n",
      " |  nesterovs_momentum : bool, default=True\n",
      " |      Whether to use Nesterov's momentum. Only used when solver='sgd' and\n",
      " |      momentum > 0.\n",
      " |  \n",
      " |  early_stopping : bool, default=False\n",
      " |      Whether to use early stopping to terminate training when validation\n",
      " |      score is not improving. If set to true, it will automatically set\n",
      " |      aside 10% of training data as validation and terminate training when\n",
      " |      validation score is not improving by at least tol for\n",
      " |      ``n_iter_no_change`` consecutive epochs. The split is stratified,\n",
      " |      except in a multilabel setting.\n",
      " |      If early stopping is False, then the training stops when the training\n",
      " |      loss does not improve by more than tol for n_iter_no_change consecutive\n",
      " |      passes over the training set.\n",
      " |      Only effective when solver='sgd' or 'adam'\n",
      " |  \n",
      " |  validation_fraction : float, default=0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Must be between 0 and 1.\n",
      " |      Only used if early_stopping is True\n",
      " |  \n",
      " |  beta_1 : float, default=0.9\n",
      " |      Exponential decay rate for estimates of first moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'\n",
      " |  \n",
      " |  beta_2 : float, default=0.999\n",
      " |      Exponential decay rate for estimates of second moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'\n",
      " |  \n",
      " |  epsilon : float, default=1e-8\n",
      " |      Value for numerical stability in adam. Only used when solver='adam'\n",
      " |  \n",
      " |  n_iter_no_change : int, default=10\n",
      " |      Maximum number of epochs to not meet ``tol`` improvement.\n",
      " |      Only effective when solver='sgd' or 'adam'\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  max_fun : int, default=15000\n",
      " |      Only used when solver='lbfgs'. Maximum number of loss function calls.\n",
      " |      The solver iterates until convergence (determined by 'tol'), number\n",
      " |      of iterations reaches max_iter, or this number of loss function calls.\n",
      " |      Note that number of loss function calls will be greater than or equal\n",
      " |      to the number of iterations for the `MLPClassifier`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : ndarray or list of ndarray of shape (n_classes,)\n",
      " |      Class labels for each output.\n",
      " |  \n",
      " |  loss_ : float\n",
      " |      The current loss computed with the loss function.\n",
      " |  \n",
      " |  best_loss_ : float\n",
      " |      The minimum loss reached by the solver throughout fitting.\n",
      " |  \n",
      " |  loss_curve_ : list of shape (`n_iter_`,)\n",
      " |      The ith element in the list represents the loss at the ith iteration.\n",
      " |  \n",
      " |  t_ : int\n",
      " |      The number of training samples seen by the solver during fitting.\n",
      " |  \n",
      " |  coefs_ : list of shape (n_layers - 1,)\n",
      " |      The ith element in the list represents the weight matrix corresponding\n",
      " |      to layer i.\n",
      " |  \n",
      " |  intercepts_ : list of shape (n_layers - 1,)\n",
      " |      The ith element in the list represents the bias vector corresponding to\n",
      " |      layer i + 1.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      The number of iterations the solver has run.\n",
      " |  \n",
      " |  n_layers_ : int\n",
      " |      Number of layers.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      Number of outputs.\n",
      " |  \n",
      " |  out_activation_ : str\n",
      " |      Name of the output activation function.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.neural_network import MLPClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> from sklearn.model_selection import train_test_split\n",
      " |  >>> X, y = make_classification(n_samples=100, random_state=1)\n",
      " |  >>> X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
      " |  ...                                                     random_state=1)\n",
      " |  >>> clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
      " |  >>> clf.predict_proba(X_test[:1])\n",
      " |  array([[0.038..., 0.961...]])\n",
      " |  >>> clf.predict(X_test[:5, :])\n",
      " |  array([1, 0, 1, 0, 1])\n",
      " |  >>> clf.score(X_test, y_test)\n",
      " |  0.8...\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  MLPClassifier trains iteratively since at each time step\n",
      " |  the partial derivatives of the loss function with respect to the model\n",
      " |  parameters are computed to update the parameters.\n",
      " |  \n",
      " |  It can also have a regularization term added to the loss function\n",
      " |  that shrinks model parameters to prevent overfitting.\n",
      " |  \n",
      " |  This implementation works with data represented as dense numpy arrays or\n",
      " |  sparse scipy arrays of floating point values.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Hinton, Geoffrey E.\n",
      " |      \"Connectionist learning procedures.\" Artificial intelligence 40.1\n",
      " |      (1989): 185-234.\n",
      " |  \n",
      " |  Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of\n",
      " |      training deep feedforward neural networks.\" International Conference\n",
      " |      on Artificial Intelligence and Statistics. 2010.\n",
      " |  \n",
      " |  He, Kaiming, et al. \"Delving deep into rectifiers: Surpassing human-level\n",
      " |      performance on imagenet classification.\" arXiv preprint\n",
      " |      arXiv:1502.01852 (2015).\n",
      " |  \n",
      " |  Kingma, Diederik, and Jimmy Ba. \"Adam: A method for stochastic\n",
      " |      optimization.\" arXiv preprint arXiv:1412.6980 (2014).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MLPClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseMultilayerPerceptron\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the multi-layer perceptron classifier\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray, shape (n_samples,) or (n_samples, n_classes)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Return the log of probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      log_y_prob : ndarray of shape (n_samples, n_classes)\n",
      " |          The predicted log-probability of the sample for each class\n",
      " |          in the model, where classes are ordered as they are in\n",
      " |          `self.classes_`. Equivalent to log(predict_proba(X))\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_prob : ndarray of shape (n_samples, n_classes)\n",
      " |          The predicted probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in `self.classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  partial_fit\n",
      " |      Update the model with a single iteration over the given data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target values.\n",
      " |      \n",
      " |      classes : array of shape (n_classes,), default=None\n",
      " |          Classes across all calls to partial_fit.\n",
      " |          Can be obtained via `np.unique(y_all)`, where y_all is the\n",
      " |          target vector of the entire dataset.\n",
      " |          This argument is required for the first call to partial_fit\n",
      " |          and can be omitted in the subsequent calls.\n",
      " |          Note that y doesn't need to contain all labels in `classes`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseMultilayerPerceptron:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model to data matrix X and target(s) y.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray or sparse matrix of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01720bc6-9dd2-4537-888e-817c59fc0fea",
=======
   "execution_count": null,
   "id": "ae2164d7-9774-4d2f-8fc7-2c0e937e959c",
>>>>>>> 1b841e74b9b1cb6c6b41768be18ff9ae5c20c481
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3 (ipykernel)",
=======
   "display_name": "Python 3",
>>>>>>> 1b841e74b9b1cb6c6b41768be18ff9ae5c20c481
   "language": "python",
   "name": "python3"
  },
  "language_info": {
<<<<<<< HEAD
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
=======
   "name": ""
>>>>>>> 1b841e74b9b1cb6c6b41768be18ff9ae5c20c481
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
