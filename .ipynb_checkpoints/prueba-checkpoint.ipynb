{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a489882-614b-4f70-a967-250409fa2c7f",
   "metadata": {},
   "source": [
    "# Primeros métodos de aprendizaje supervisado en Sciki-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03041fa6-89de-4cce-b9ab-1c37d00fcb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mglearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d5bd6-2d0c-4a84-8f9f-242f3675ba48",
   "metadata": {},
   "source": [
    "#### KNeighborsRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd60732-1e26-49af-90fa-f393236831d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#Wave es un dataset sintético, útil para resaltar características de los algortimos, en este caso KNeighborsRegressor\n",
    "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
    "# split the wave dataset into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# instantiate the model and set the number of neighbors to consider to 3\n",
    "reg = KNeighborsRegressor(n_neighbors=3)\n",
    "# fit the model using the training data and training targets\n",
    "reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc3c55-6767-48bd-94b5-d5a9d02a26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "# Se evalúa \n",
    "print(\"Test set predictions:\\n{}\".format(reg.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca77db-300a-47a7-9f89-38e6671e1545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "#Aquí se pide el coeficiente de determinación R^2\n",
    "print(\"Test set R^2: {:.2f}\".format(reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9479e10-e1fa-4d4f-9b8d-cfd05487432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "#Se compara el desempeño en Wave de KNeighborsRegressor con 1, 3 y 9 vecinos\n",
    "\n",
    "#Se crean los tres planos en que se imprimirán los resultados sobre el dataset Wave\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# create 1,000 data points, evenly spaced between -3 and 3\n",
    "# esta línea es nuestro conjunto de prueba\n",
    "line = np.linspace(-3, 3, 1000).reshape(-1, 1)\n",
    "\n",
    "\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    "    # make predictions using 1, 3, or 9 neighbors\n",
    "    reg = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    reg.fit(X_train, y_train)\n",
    "    ax.plot(line, reg.predict(line))\n",
    "    ax.plot(X_train, y_train, '^', c=mglearn.cm2(0), markersize=8)\n",
    "    ax.plot(X_test, y_test, 'v', c=mglearn.cm2(1), markersize=8)\n",
    "    ax.set_title(\n",
    "    \"{} neighbor(s)\\n train score: {:.2f} test score: {:.2f}\".format(\n",
    "    n_neighbors, reg.score(X_train, y_train),\n",
    "    reg.score(X_test, y_test)))\n",
    "    ax.set_xlabel(\"Feature\")\n",
    "    ax.set_ylabel(\"Target\")\n",
    "axes[0].legend([\"Model predictions\", \"Training data/target\",\n",
    " \"Test data/target\"], loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31dd24-7813-4f60-96e5-6d716f560354",
   "metadata": {},
   "source": [
    "#### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3dbc47-aeb9-46b9-a349-39c92585c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X, y = mglearn.datasets.make_wave(n_samples=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "lr = LinearRegression().fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e0c3e-b3a0-4d7e-b2bf-5f8d5aee7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "# _.coef_ nos da los coeficientes de la ecuación lineal que dada por el modelo. _intercept_ nos da el término independiente. \n",
    "print(\"lr.coef_: {}\".format(lr.coef_))\n",
    "print(\"lr.intercept_: {}\".format(lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283e9c5-7aff-4b40-bd66-2cf9c7e29235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "#Se compara el ajuste del modelo al conjunto de entrenamiento con el desempeño en el conjunto de prueba\n",
    "print(\"Training set score: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe50f6d-bcc6-4e82-9166-8a5f2c5eca52",
   "metadata": {},
   "source": [
    "#### Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bf54a-583a-4f70-960d-ce8d281b2145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "#Ridge aplicado a Boston Housing\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47fb17-2d32-4fc6-a1de-8bd6c22d57e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "ridge10 = Ridge(alpha=10).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge10.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge10.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd02950e-63bf-4d5a-b09d-4ccdf5958d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge01.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge01.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1552f346-6792-491a-8250-aef8170e18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12\n",
    "# Se comparan los coeficientes del modelo según varía alpha\n",
    "plt.plot(ridge.coef_, 's', label=\"Ridge alpha=1\")\n",
    "plt.plot(ridge10.coef_, '^', label=\"Ridge alpha=10\")\n",
    "plt.plot(ridge01.coef_, 'v', label=\"Ridge alpha=0.1\")\n",
    "plt.plot(lr.coef_, 'o', label=\"LinearRegression\")\n",
    "plt.xlabel(\"Coefficient index\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n",
    "plt.hlines(0, 0, len(lr.coef_))\n",
    "plt.ylim(-25, 25)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd34bb17-b3d1-4873-aeae-a36e94e7b689",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fe7912-eb00-4bba-a854-9fb56b0c17c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "#Se aplica el algoritmo Lasso \n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso.score(X_test, y_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso.coef_ != 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f64768-b48b-4b26-8f40-c464611d0639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "# we increase the default setting of \"max_iter\",\n",
    "# otherwise the model would warn us that we should increase max_iter.\n",
    "lasso001 = Lasso(alpha=0.01, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso001.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso001.score(X_test, y_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso001.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba82572-764d-4eb5-b91c-a727798e40ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15\n",
    "lasso00001 = Lasso(alpha=0.0001, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso00001.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso00001.score(X_test, y_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso00001.coef_ != 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9e0cc-1877-4920-b18d-fda46a3c05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16\n",
    "# Se comparan los coeficientes del modelo según varía alpha\n",
    "\n",
    "plt.plot(lasso.coef_, 's', label=\"Lasso alpha=1\")\n",
    "plt.plot(lasso001.coef_, '^', label=\"Lasso alpha=0.01\")\n",
    "plt.plot(lasso00001.coef_, 'v', label=\"Lasso alpha=0.0001\")\n",
    "plt.plot(ridge01.coef_, 'o', label=\"Ridge alpha=0.1\")\n",
    "plt.legend(ncol=2, loc=(0, 1.05))\n",
    "plt.ylim(-25, 25)\n",
    "plt.xlabel(\"Coefficient index\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43789e3d-8add-4563-b572-bd1deb144d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "593e8c08-65fe-4604-85c4-5294dc34f8b3",
   "metadata": {},
   "source": [
    "#### LinearSVC y LogisticRegression \n",
    "\n",
    "El objetivo de estos métodos es dividir el espacio muestral por medio de una recta, un plano o un hiperplano. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71858c7-a357-440b-a0ff-0f5734b29e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17 \n",
    "# Se comparan los modelos LogisticRegression y LinearSVC en el dataset sintético forge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "for model, ax in zip([LinearSVC(), LogisticRegression()], axes):\n",
    "    clf = model.fit(X, y)\n",
    "    mglearn.plots.plot_2d_separator(clf, X, fill=False, eps=0.5,\n",
    "    ax=ax, alpha=.7)\n",
    "    mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)\n",
    "    ax.set_title(\"{}\".format(clf.__class__.__name__))\n",
    "    ax.set_xlabel(\"Feature 0\")\n",
    "    ax.set_ylabel(\"Feature 1\")\n",
    "axes[0].legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f980837c-41ed-4e31-a956-64361511093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18\n",
    "#Aquí se aplica LogisticRegression a Breast Cancer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c7305-371a-412b-92db-e79d6445b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19\n",
    "logreg100 = LogisticRegression(C=100).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg100.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg100.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9829b0-7a55-4957-a569-686de50be834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20\n",
    "logreg001 = LogisticRegression(C=0.01).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg001.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg001.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafd47f0-66e3-4ad6-8161-774e49202d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#21\n",
    "#Se comparan los coeficientes de los tres modelos creados de LogisticRegression\n",
    "plt.plot(logreg.coef_.T, 'o', label=\"C=1\")\n",
    "plt.plot(logreg100.coef_.T, '^', label=\"C=100\")\n",
    "plt.plot(logreg001.coef_.T, 'v', label=\"C=0.001\")\n",
    "plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation=90)\n",
    "plt.hlines(0, 0, cancer.data.shape[1])\n",
    "plt.ylim(-5, 5)\n",
    "plt.xlabel(\"Coefficient index\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4147aa61-a130-487a-a54e-25975010a273",
   "metadata": {},
   "source": [
    "#### SVC para más de dos clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e5a559-a9b1-4fdb-808a-338a3d13757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22\n",
    "from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(random_state=42)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.legend([\"Class 0\", \"Class 1\", \"Class 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf1353-dccc-489a-9c2f-e82e99e048c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#23\n",
    "# Ahora el _.coef_ es una matriz e _.intercept_ un vector\n",
    "linear_svm = LinearSVC().fit(X, y)\n",
    "print(\"Coefficient shape: \", linear_svm.coef_.shape)\n",
    "print(\"Intercept shape: \", linear_svm.intercept_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d0f9f7-9083-455b-8215-dfff040339de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#24\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "line = np.linspace(-15, 15)\n",
    "for coef, intercept, color in zip(linear_svm.coef_, linear_svm.intercept_,\n",
    "    ['b', 'r', 'g']):\n",
    "    plt.plot(line, -(line * coef[0] + intercept) / coef[1], c=color)\n",
    "plt.ylim(-10, 15)\n",
    "plt.xlim(-10, 8)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n",
    "plt.legend(['Class 0', 'Class 1', 'Class 2', 'Line class 0', 'Line class 1',\n",
    " 'Line class 2'], loc=(1.01, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e295d948-9975-4fbe-9e92-6eec926fb088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#25\n",
    "mglearn.plots.plot_2d_classification(linear_svm, X, fill=True, alpha=.7)\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "line = np.linspace(-15, 15)\n",
    "for coef, intercept, color in zip(linear_svm.coef_, linear_svm.intercept_,\n",
    "    ['b', 'r', 'g']):\n",
    "    plt.plot(line, -(line * coef[0] + intercept) / coef[1], c=color)\n",
    "plt.legend(['Class 0', 'Class 1', 'Class 2', 'Line class 0', 'Line class 1',\n",
    " 'Line class 2'], loc=(1.01, 0.3))\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34d7709-9f1d-43c5-b405-fed2d7ddae67",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier revisitado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f4b0f-ec28-4e61-b58e-9df724c76f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "# Se aplica el algoritmo en el dataset sintético forge variando el número de vecinos\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    " # the fit method returns the object self, so we can instantiate\n",
    " # and fit in one line\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X,y)\n",
    "    mglearn.plots.plot_2d_separator(clf, X, fill=True, eps=0.5, ax=ax, alpha=.4)\n",
    "    mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)\n",
    "    ax.set_title(\"{} neighbor(s)\".format(n_neighbors))\n",
    "    ax.set_xlabel(\"feature 0\")\n",
    "    ax.set_ylabel(\"feature 1\")\n",
    "axes[0].legend(loc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a7212-14e5-4676-b2a4-a9509d4ef47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "#Se evalúa el logaritmo en breast_cancer con hasta diez vecinos \n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    " cancer.data, cancer.target, stratify=cancer.target, random_state=66)\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10\n",
    "neighbors_settings = range(1, 11)\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d06833-6555-40bc-afe3-723436477558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
